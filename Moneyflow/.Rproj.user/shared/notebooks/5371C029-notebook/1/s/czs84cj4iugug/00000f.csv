"0",""
"0","initial_set_variables <- c("
"0","  'payer_age_num',"
"0","  'payer_ind_size',"
"0","  'seller_ind_size',"
"0","  'offer_cost_percent',"
"0","  'payer_risika_score_num',"
"0","  'seller_age_num',"
"0","  'invoice_amount',"
"0","  'inv_due2today',"
"0","  'inv_iss2due',"
"0","  'seller_risika_score',"
"0","  'seller_danish_pep_num',"
"0","  'seller_comp_size',"
"0","  'payer_comp_size',"
"0","  "
"0","  'response'"
"0",")"
"0",""
"0","set.seed(101) # Set Seed so that same sample can be reproduced in future also"
"0","# Now Selecting 75% of data as sample from total 'n' rows of the data  "
"0","sample <- sample.int(n = nrow(invoices_clean), size = floor(.75*nrow(invoices_clean)), replace = F)"
"0","train_dat <- invoices_clean[sample, initial_set_variables]"
"0","test_dat  <- invoices_clean[-sample,initial_set_variables ]"
"0",""
"0","mean(train_dat$response)"
"1","[1]"
"1"," 0.05035765"
"1","
"
"0","mean(test_dat$response)"
"1","[1]"
"1"," 0.04933505"
"1","
"
"0","xg <- XGBTrainer$new(early_stopping = 50,"
"0","                     objective = 'binary:logistic')"
"0","xgb_model_1 <- GridSearchCV$new(trainer = xg,"
"0","                                parameters = list(n_estimators = c(1500),"
"0","                                                  learning_rate = c(0.01, 0.1),"
"0","                                                  max_depth = c(5,2,10),"
"0","                                                  min_child_weight = c(5,10)),"
"0","                                n_folds = 3,"
"0","                                scoring = c('auc'))"
"0",""
"0",""
"0","xgb_model_1$fit(train_dat , ""response"")"
"1","[1]"
"1"," ""entering grid search"""
"1","
"
"1","[1]"
"1"," ""In total, 12 models will be trained"""
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:17:18] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:17:18] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684250"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.392308"
"1"," "
"1","
"
"1","[101]	train-logloss:0.254386"
"1"," "
"1","
"
"1","[151]	train-logloss:0.181407"
"1"," "
"1","
"
"1","[201]	train-logloss:0.140643"
"1"," "
"1","
"
"1","[251]	train-logloss:0.116009"
"1"," "
"1","
"
"1","[301]	train-logloss:0.101345"
"1"," "
"1","
"
"1","[351]	train-logloss:0.091576"
"1"," "
"1","
"
"1","[401]	train-logloss:0.085515"
"1"," "
"1","
"
"1","[451]	train-logloss:0.080415"
"1"," "
"1","
"
"1","[501]	train-logloss:0.076578"
"1"," "
"1","
"
"1","[551]	train-logloss:0.072958"
"1"," "
"1","
"
"1","[601]	train-logloss:0.070140"
"1"," "
"1","
"
"1","[651]	train-logloss:0.067567"
"1"," "
"1","
"
"1","[701]	train-logloss:0.064913"
"1"," "
"1","
"
"1","[751]	train-logloss:0.062828"
"1"," "
"1","
"
"1","[801]	train-logloss:0.060527"
"1"," "
"1","
"
"1","[851]	train-logloss:0.058523"
"1"," "
"1","
"
"1","[901]	train-logloss:0.056911"
"1"," "
"1","
"
"1","[951]	train-logloss:0.055231"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.053687"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.052295"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.051110"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.049994"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.049019"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.048146"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.047270"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.046442"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.045643"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.044823"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.044238"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:17:29] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:17:29] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684238"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.392332"
"1"," "
"1","
"
"1","[101]	train-logloss:0.255459"
"1"," "
"1","
"
"1","[151]	train-logloss:0.182667"
"1"," "
"1","
"
"1","[201]	train-logloss:0.142033"
"1"," "
"1","
"
"1","[251]	train-logloss:0.116848"
"1"," "
"1","
"
"1","[301]	train-logloss:0.101004"
"1"," "
"1","
"
"1","[351]	train-logloss:0.091034"
"1"," "
"1","
"
"1","[401]	train-logloss:0.083856"
"1"," "
"1","
"
"1","[451]	train-logloss:0.079387"
"1"," "
"1","
"
"1","[501]	train-logloss:0.075460"
"1"," "
"1","
"
"1","[551]	train-logloss:0.072086"
"1"," "
"1","
"
"1","[601]	train-logloss:0.069679"
"1"," "
"1","
"
"1","[651]	train-logloss:0.067765"
"1"," "
"1","
"
"1","[701]	train-logloss:0.065968"
"1"," "
"1","
"
"1","[751]	train-logloss:0.064147"
"1"," "
"1","
"
"1","[801]	train-logloss:0.062344"
"1"," "
"1","
"
"1","[851]	train-logloss:0.060642"
"1"," "
"1","
"
"1","[901]	train-logloss:0.059050"
"1"," "
"1","
"
"1","[951]	train-logloss:0.057396"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.056161"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.055027"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.053891"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.052633"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.051503"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.050550"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.049546"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.048471"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.047543"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.046736"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.045865"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:17:39] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:17:39] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684168"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.388943"
"1"," "
"1","
"
"1","[101]	train-logloss:0.250171"
"1"," "
"1","
"
"1","[151]	train-logloss:0.175988"
"1"," "
"1","
"
"1","[201]	train-logloss:0.133382"
"1"," "
"1","
"
"1","[251]	train-logloss:0.108395"
"1"," "
"1","
"
"1","[301]	train-logloss:0.093898"
"1"," "
"1","
"
"1","[351]	train-logloss:0.084708"
"1"," "
"1","
"
"1","[401]	train-logloss:0.077303"
"1"," "
"1","
"
"1","[451]	train-logloss:0.072281"
"1"," "
"1","
"
"1","[501]	train-logloss:0.068651"
"1"," "
"1","
"
"1","[551]	train-logloss:0.065172"
"1"," "
"1","
"
"1","[601]	train-logloss:0.061671"
"1"," "
"1","
"
"1","[651]	train-logloss:0.059104"
"1"," "
"1","
"
"1","[701]	train-logloss:0.056427"
"1"," "
"1","
"
"1","[751]	train-logloss:0.054385"
"1"," "
"1","
"
"1","[801]	train-logloss:0.052455"
"1"," "
"1","
"
"1","[851]	train-logloss:0.050804"
"1"," "
"1","
"
"1","[901]	train-logloss:0.049360"
"1"," "
"1","
"
"1","[951]	train-logloss:0.048022"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.046687"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.045401"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.044317"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.043140"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.042106"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.041058"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.040261"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.039482"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.038667"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.037857"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.037054"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:17:53] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:17:53] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.608164"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.074473"
"1"," "
"1","
"
"1","[101]	train-logloss:0.053039"
"1"," "
"1","
"
"1","[151]	train-logloss:0.042760"
"1"," "
"1","
"
"1","[201]	train-logloss:0.035332"
"1"," "
"1","
"
"1","[251]	train-logloss:0.030051"
"1"," "
"1","
"
"1","[301]	train-logloss:0.026067"
"1"," "
"1","
"
"1","[351]	train-logloss:0.023069"
"1"," "
"1","
"
"1","[401]	train-logloss:0.020730"
"1"," "
"1","
"
"1","[451]	train-logloss:0.019104"
"1"," "
"1","
"
"1","[501]	train-logloss:0.017760"
"1"," "
"1","
"
"1","[551]	train-logloss:0.016576"
"1"," "
"1","
"
"1","[601]	train-logloss:0.015608"
"1"," "
"1","
"
"1","[651]	train-logloss:0.014783"
"1"," "
"1","
"
"1","[701]	train-logloss:0.014168"
"1"," "
"1","
"
"1","[751]	train-logloss:0.013635"
"1"," "
"1","
"
"1","[801]	train-logloss:0.013148"
"1"," "
"1","
"
"1","[851]	train-logloss:0.012715"
"1"," "
"1","
"
"1","[901]	train-logloss:0.012339"
"1"," "
"1","
"
"1","[951]	train-logloss:0.012023"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.011726"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.011463"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.011211"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.010997"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.010799"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.010603"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.010440"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.010289"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.010144"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.010017"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.009893"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:18:05] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:18:05] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.608064"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.073712"
"1"," "
"1","
"
"1","[101]	train-logloss:0.054198"
"1"," "
"1","
"
"1","[151]	train-logloss:0.043357"
"1"," "
"1","
"
"1","[201]	train-logloss:0.036682"
"1"," "
"1","
"
"1","[251]	train-logloss:0.031471"
"1"," "
"1","
"
"1","[301]	train-logloss:0.027636"
"1"," "
"1","
"
"1","[351]	train-logloss:0.024927"
"1"," "
"1","
"
"1","[401]	train-logloss:0.022680"
"1"," "
"1","
"
"1","[451]	train-logloss:0.020870"
"1"," "
"1","
"
"1","[501]	train-logloss:0.019406"
"1"," "
"1","
"
"1","[551]	train-logloss:0.018184"
"1"," "
"1","
"
"1","[601]	train-logloss:0.017215"
"1"," "
"1","
"
"1","[651]	train-logloss:0.016403"
"1"," "
"1","
"
"1","[701]	train-logloss:0.015696"
"1"," "
"1","
"
"1","[751]	train-logloss:0.015082"
"1"," "
"1","
"
"1","[801]	train-logloss:0.014570"
"1"," "
"1","
"
"1","[851]	train-logloss:0.014082"
"1"," "
"1","
"
"1","[901]	train-logloss:0.013678"
"1"," "
"1","
"
"1","[951]	train-logloss:0.013283"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.012939"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.012616"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.012328"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.012081"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.011848"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.011652"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.011466"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.011293"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.011149"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.011000"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.010864"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:18:16] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:18:16] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.607392"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.067264"
"1"," "
"1","
"
"1","[101]	train-logloss:0.046039"
"1"," "
"1","
"
"1","[151]	train-logloss:0.036555"
"1"," "
"1","
"
"1","[201]	train-logloss:0.030052"
"1"," "
"1","
"
"1","[251]	train-logloss:0.026046"
"1"," "
"1","
"
"1","[301]	train-logloss:0.022751"
"1"," "
"1","
"
"1","[351]	train-logloss:0.020522"
"1"," "
"1","
"
"1","[401]	train-logloss:0.018636"
"1"," "
"1","
"
"1","[451]	train-logloss:0.017142"
"1"," "
"1","
"
"1","[501]	train-logloss:0.015945"
"1"," "
"1","
"
"1","[551]	train-logloss:0.014994"
"1"," "
"1","
"
"1","[601]	train-logloss:0.014188"
"1"," "
"1","
"
"1","[651]	train-logloss:0.013512"
"1"," "
"1","
"
"1","[701]	train-logloss:0.012903"
"1"," "
"1","
"
"1","[751]	train-logloss:0.012424"
"1"," "
"1","
"
"1","[801]	train-logloss:0.011990"
"1"," "
"1","
"
"1","[851]	train-logloss:0.011628"
"1"," "
"1","
"
"1","[901]	train-logloss:0.011290"
"1"," "
"1","
"
"1","[951]	train-logloss:0.010986"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.010724"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.010494"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.010272"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.010083"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.009899"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.009730"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.009586"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.009443"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.009318"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.009186"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.009074"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:18:26] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:18:26] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684317"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.395451"
"1"," "
"1","
"
"1","[101]	train-logloss:0.261662"
"1"," "
"1","
"
"1","[151]	train-logloss:0.193472"
"1"," "
"1","
"
"1","[201]	train-logloss:0.154834"
"1"," "
"1","
"
"1","[251]	train-logloss:0.134235"
"1"," "
"1","
"
"1","[301]	train-logloss:0.122407"
"1"," "
"1","
"
"1","[351]	train-logloss:0.114426"
"1"," "
"1","
"
"1","[401]	train-logloss:0.109379"
"1"," "
"1","
"
"1","[451]	train-logloss:0.106555"
"1"," "
"1","
"
"1","[501]	train-logloss:0.104151"
"1"," "
"1","
"
"1","[551]	train-logloss:0.102154"
"1"," "
"1","
"
"1","[601]	train-logloss:0.100494"
"1"," "
"1","
"
"1","[651]	train-logloss:0.099127"
"1"," "
"1","
"
"1","[701]	train-logloss:0.097695"
"1"," "
"1","
"
"1","[751]	train-logloss:0.096278"
"1"," "
"1","
"
"1","[801]	train-logloss:0.094807"
"1"," "
"1","
"
"1","[851]	train-logloss:0.093369"
"1"," "
"1","
"
"1","[901]	train-logloss:0.092065"
"1"," "
"1","
"
"1","[951]	train-logloss:0.090851"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.089765"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.088713"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.087749"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.086840"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.086040"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.085252"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.084487"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.083754"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.083041"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.082310"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.081634"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:18:33] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:18:33] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684407"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.398674"
"1"," "
"1","
"
"1","[101]	train-logloss:0.266631"
"1"," "
"1","
"
"1","[151]	train-logloss:0.194926"
"1"," "
"1","
"
"1","[201]	train-logloss:0.156146"
"1"," "
"1","
"
"1","[251]	train-logloss:0.135881"
"1"," "
"1","
"
"1","[301]	train-logloss:0.124679"
"1"," "
"1","
"
"1","[351]	train-logloss:0.117471"
"1"," "
"1","
"
"1","[401]	train-logloss:0.112535"
"1"," "
"1","
"
"1","[451]	train-logloss:0.108691"
"1"," "
"1","
"
"1","[501]	train-logloss:0.106105"
"1"," "
"1","
"
"1","[551]	train-logloss:0.103833"
"1"," "
"1","
"
"1","[601]	train-logloss:0.101677"
"1"," "
"1","
"
"1","[651]	train-logloss:0.099742"
"1"," "
"1","
"
"1","[701]	train-logloss:0.097954"
"1"," "
"1","
"
"1","[751]	train-logloss:0.096172"
"1"," "
"1","
"
"1","[801]	train-logloss:0.094477"
"1"," "
"1","
"
"1","[851]	train-logloss:0.092993"
"1"," "
"1","
"
"1","[901]	train-logloss:0.091673"
"1"," "
"1","
"
"1","[951]	train-logloss:0.090393"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.089339"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.088348"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.087508"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.086683"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.086029"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.085276"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.084507"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.083808"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.082984"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.082407"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.081798"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:18:39] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:18:39] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684333"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.396184"
"1"," "
"1","
"
"1","[101]	train-logloss:0.262935"
"1"," "
"1","
"
"1","[151]	train-logloss:0.187328"
"1"," "
"1","
"
"1","[201]	train-logloss:0.147097"
"1"," "
"1","
"
"1","[251]	train-logloss:0.126110"
"1"," "
"1","
"
"1","[301]	train-logloss:0.114136"
"1"," "
"1","
"
"1","[351]	train-logloss:0.107206"
"1"," "
"1","
"
"1","[401]	train-logloss:0.102405"
"1"," "
"1","
"
"1","[451]	train-logloss:0.098761"
"1"," "
"1","
"
"1","[501]	train-logloss:0.095778"
"1"," "
"1","
"
"1","[551]	train-logloss:0.093293"
"1"," "
"1","
"
"1","[601]	train-logloss:0.091182"
"1"," "
"1","
"
"1","[651]	train-logloss:0.089101"
"1"," "
"1","
"
"1","[701]	train-logloss:0.087202"
"1"," "
"1","
"
"1","[751]	train-logloss:0.085342"
"1"," "
"1","
"
"1","[801]	train-logloss:0.083679"
"1"," "
"1","
"
"1","[851]	train-logloss:0.082238"
"1"," "
"1","
"
"1","[901]	train-logloss:0.080970"
"1"," "
"1","
"
"1","[951]	train-logloss:0.079832"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.078741"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.077762"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.076687"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.075702"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.074826"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.074020"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.073283"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.072478"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.071713"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.070927"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.070138"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:18:45] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:18:45] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.608813"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.102802"
"1"," "
"1","
"
"1","[101]	train-logloss:0.088341"
"1"," "
"1","
"
"1","[151]	train-logloss:0.079922"
"1"," "
"1","
"
"1","[201]	train-logloss:0.074080"
"1"," "
"1","
"
"1","[251]	train-logloss:0.068176"
"1"," "
"1","
"
"1","[301]	train-logloss:0.063531"
"1"," "
"1","
"
"1","[351]	train-logloss:0.059986"
"1"," "
"1","
"
"1","[401]	train-logloss:0.057025"
"1"," "
"1","
"
"1","[451]	train-logloss:0.054686"
"1"," "
"1","
"
"1","[501]	train-logloss:0.052676"
"1"," "
"1","
"
"1","[551]	train-logloss:0.050552"
"1"," "
"1","
"
"1","[601]	train-logloss:0.048951"
"1"," "
"1","
"
"1","[651]	train-logloss:0.047579"
"1"," "
"1","
"
"1","[701]	train-logloss:0.045996"
"1"," "
"1","
"
"1","[751]	train-logloss:0.044464"
"1"," "
"1","
"
"1","[801]	train-logloss:0.043095"
"1"," "
"1","
"
"1","[851]	train-logloss:0.041817"
"1"," "
"1","
"
"1","[901]	train-logloss:0.040595"
"1"," "
"1","
"
"1","[951]	train-logloss:0.039465"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.038469"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.037574"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.036621"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.035651"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.034816"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.033986"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.033257"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.032593"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.031818"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.031152"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.030502"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:18:51] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:18:51] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.609670"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.104049"
"1"," "
"1","
"
"1","[101]	train-logloss:0.089130"
"1"," "
"1","
"
"1","[151]	train-logloss:0.080756"
"1"," "
"1","
"
"1","[201]	train-logloss:0.074683"
"1"," "
"1","
"
"1","[251]	train-logloss:0.069882"
"1"," "
"1","
"
"1","[301]	train-logloss:0.065533"
"1"," "
"1","
"
"1","[351]	train-logloss:0.061839"
"1"," "
"1","
"
"1","[401]	train-logloss:0.058755"
"1"," "
"1","
"
"1","[451]	train-logloss:0.056016"
"1"," "
"1","
"
"1","[501]	train-logloss:0.053685"
"1"," "
"1","
"
"1","[551]	train-logloss:0.051536"
"1"," "
"1","
"
"1","[601]	train-logloss:0.049621"
"1"," "
"1","
"
"1","[651]	train-logloss:0.047815"
"1"," "
"1","
"
"1","[701]	train-logloss:0.046121"
"1"," "
"1","
"
"1","[751]	train-logloss:0.044750"
"1"," "
"1","
"
"1","[801]	train-logloss:0.043268"
"1"," "
"1","
"
"1","[851]	train-logloss:0.041916"
"1"," "
"1","
"
"1","[901]	train-logloss:0.040709"
"1"," "
"1","
"
"1","[951]	train-logloss:0.039566"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.038535"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.037533"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.036576"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.035607"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.034712"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.033942"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.033216"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.032427"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.031732"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.030999"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.030406"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:18:57] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:18:57] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.608978"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.094151"
"1"," "
"1","
"
"1","[101]	train-logloss:0.077772"
"1"," "
"1","
"
"1","[151]	train-logloss:0.069292"
"1"," "
"1","
"
"1","[201]	train-logloss:0.063226"
"1"," "
"1","
"
"1","[251]	train-logloss:0.058307"
"1"," "
"1","
"
"1","[301]	train-logloss:0.054418"
"1"," "
"1","
"
"1","[351]	train-logloss:0.051354"
"1"," "
"1","
"
"1","[401]	train-logloss:0.048571"
"1"," "
"1","
"
"1","[451]	train-logloss:0.046518"
"1"," "
"1","
"
"1","[501]	train-logloss:0.044614"
"1"," "
"1","
"
"1","[551]	train-logloss:0.042871"
"1"," "
"1","
"
"1","[601]	train-logloss:0.041326"
"1"," "
"1","
"
"1","[651]	train-logloss:0.039715"
"1"," "
"1","
"
"1","[701]	train-logloss:0.038346"
"1"," "
"1","
"
"1","[751]	train-logloss:0.036948"
"1"," "
"1","
"
"1","[801]	train-logloss:0.035774"
"1"," "
"1","
"
"1","[851]	train-logloss:0.034650"
"1"," "
"1","
"
"1","[901]	train-logloss:0.033636"
"1"," "
"1","
"
"1","[951]	train-logloss:0.032622"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.031723"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.030961"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.030189"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.029348"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.028581"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.027948"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.027209"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.026547"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.025927"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.025396"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.024885"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:19:04] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:19:04] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684211"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.390547"
"1"," "
"1","
"
"1","[101]	train-logloss:0.251378"
"1"," "
"1","
"
"1","[151]	train-logloss:0.176007"
"1"," "
"1","
"
"1","[201]	train-logloss:0.132150"
"1"," "
"1","
"
"1","[251]	train-logloss:0.105623"
"1"," "
"1","
"
"1","[301]	train-logloss:0.088816"
"1"," "
"1","
"
"1","[351]	train-logloss:0.077344"
"1"," "
"1","
"
"1","[401]	train-logloss:0.069018"
"1"," "
"1","
"
"1","[451]	train-logloss:0.063051"
"1"," "
"1","
"
"1","[501]	train-logloss:0.058804"
"1"," "
"1","
"
"1","[551]	train-logloss:0.055227"
"1"," "
"1","
"
"1","[601]	train-logloss:0.052112"
"1"," "
"1","
"
"1","[651]	train-logloss:0.049391"
"1"," "
"1","
"
"1","[701]	train-logloss:0.047187"
"1"," "
"1","
"
"1","[751]	train-logloss:0.045223"
"1"," "
"1","
"
"1","[801]	train-logloss:0.043497"
"1"," "
"1","
"
"1","[851]	train-logloss:0.041993"
"1"," "
"1","
"
"1","[901]	train-logloss:0.040547"
"1"," "
"1","
"
"1","[951]	train-logloss:0.039243"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.038005"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.036883"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.035909"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.035030"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.034171"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.033336"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.032487"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.031761"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.031029"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.030375"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.029803"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:19:27] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:19:27] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684229"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.390852"
"1"," "
"1","
"
"1","[101]	train-logloss:0.251504"
"1"," "
"1","
"
"1","[151]	train-logloss:0.175193"
"1"," "
"1","
"
"1","[201]	train-logloss:0.131621"
"1"," "
"1","
"
"1","[251]	train-logloss:0.105378"
"1"," "
"1","
"
"1","[301]	train-logloss:0.088864"
"1"," "
"1","
"
"1","[351]	train-logloss:0.077940"
"1"," "
"1","
"
"1","[401]	train-logloss:0.070077"
"1"," "
"1","
"
"1","[451]	train-logloss:0.064558"
"1"," "
"1","
"
"1","[501]	train-logloss:0.060404"
"1"," "
"1","
"
"1","[551]	train-logloss:0.056835"
"1"," "
"1","
"
"1","[601]	train-logloss:0.053924"
"1"," "
"1","
"
"1","[651]	train-logloss:0.051527"
"1"," "
"1","
"
"1","[701]	train-logloss:0.049346"
"1"," "
"1","
"
"1","[751]	train-logloss:0.047489"
"1"," "
"1","
"
"1","[801]	train-logloss:0.045704"
"1"," "
"1","
"
"1","[851]	train-logloss:0.044091"
"1"," "
"1","
"
"1","[901]	train-logloss:0.042491"
"1"," "
"1","
"
"1","[951]	train-logloss:0.041069"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.039883"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.038745"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.037673"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.036645"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.035719"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.034853"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.034055"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.033260"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.032528"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.031843"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.031210"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:19:48] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:19:48] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684102"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.386471"
"1"," "
"1","
"
"1","[101]	train-logloss:0.245378"
"1"," "
"1","
"
"1","[151]	train-logloss:0.169445"
"1"," "
"1","
"
"1","[201]	train-logloss:0.125098"
"1"," "
"1","
"
"1","[251]	train-logloss:0.099143"
"1"," "
"1","
"
"1","[301]	train-logloss:0.082849"
"1"," "
"1","
"
"1","[351]	train-logloss:0.072147"
"1"," "
"1","
"
"1","[401]	train-logloss:0.064141"
"1"," "
"1","
"
"1","[451]	train-logloss:0.058634"
"1"," "
"1","
"
"1","[501]	train-logloss:0.054505"
"1"," "
"1","
"
"1","[551]	train-logloss:0.051225"
"1"," "
"1","
"
"1","[601]	train-logloss:0.048491"
"1"," "
"1","
"
"1","[651]	train-logloss:0.046134"
"1"," "
"1","
"
"1","[701]	train-logloss:0.044090"
"1"," "
"1","
"
"1","[751]	train-logloss:0.042431"
"1"," "
"1","
"
"1","[801]	train-logloss:0.040946"
"1"," "
"1","
"
"1","[851]	train-logloss:0.039563"
"1"," "
"1","
"
"1","[901]	train-logloss:0.038254"
"1"," "
"1","
"
"1","[951]	train-logloss:0.036990"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.035956"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.035014"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.034086"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.033178"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.032343"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.031497"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.030721"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.030039"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.029373"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.028747"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.028159"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:20:08] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:20:08] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.607799"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.057194"
"1"," "
"1","
"
"1","[101]	train-logloss:0.037627"
"1"," "
"1","
"
"1","[151]	train-logloss:0.029389"
"1"," "
"1","
"
"1","[201]	train-logloss:0.024663"
"1"," "
"1","
"
"1","[251]	train-logloss:0.021377"
"1"," "
"1","
"
"1","[301]	train-logloss:0.019178"
"1"," "
"1","
"
"1","[351]	train-logloss:0.017593"
"1"," "
"1","
"
"1","[401]	train-logloss:0.016345"
"1"," "
"1","
"
"1","[451]	train-logloss:0.015383"
"1"," "
"1","
"
"1","[501]	train-logloss:0.014603"
"1"," "
"1","
"
"1","[551]	train-logloss:0.013949"
"1"," "
"1","
"
"1","[601]	train-logloss:0.013360"
"1"," "
"1","
"
"1","[651]	train-logloss:0.012908"
"1"," "
"1","
"
"1","[701]	train-logloss:0.012509"
"1"," "
"1","
"
"1","[751]	train-logloss:0.012138"
"1"," "
"1","
"
"1","[801]	train-logloss:0.011811"
"1"," "
"1","
"
"1","[851]	train-logloss:0.011549"
"1"," "
"1","
"
"1","[901]	train-logloss:0.011297"
"1"," "
"1","
"
"1","[951]	train-logloss:0.011066"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.010869"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.010679"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.010517"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.010358"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.010209"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.010078"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.009950"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.009837"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.009731"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.009632"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.009536"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:20:21] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:20:21] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.607976"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.059132"
"1"," "
"1","
"
"1","[101]	train-logloss:0.038941"
"1"," "
"1","
"
"1","[151]	train-logloss:0.030941"
"1"," "
"1","
"
"1","[201]	train-logloss:0.026089"
"1"," "
"1","
"
"1","[251]	train-logloss:0.022969"
"1"," "
"1","
"
"1","[301]	train-logloss:0.020734"
"1"," "
"1","
"
"1","[351]	train-logloss:0.019095"
"1"," "
"1","
"
"1","[401]	train-logloss:0.017832"
"1"," "
"1","
"
"1","[451]	train-logloss:0.016802"
"1"," "
"1","
"
"1","[501]	train-logloss:0.015961"
"1"," "
"1","
"
"1","[551]	train-logloss:0.015248"
"1"," "
"1","
"
"1","[601]	train-logloss:0.014599"
"1"," "
"1","
"
"1","[651]	train-logloss:0.014097"
"1"," "
"1","
"
"1","[701]	train-logloss:0.013627"
"1"," "
"1","
"
"1","[751]	train-logloss:0.013239"
"1"," "
"1","
"
"1","[801]	train-logloss:0.012899"
"1"," "
"1","
"
"1","[851]	train-logloss:0.012583"
"1"," "
"1","
"
"1","[901]	train-logloss:0.012304"
"1"," "
"1","
"
"1","[951]	train-logloss:0.012069"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.011848"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.011653"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.011473"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.011298"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.011135"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.010980"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.010840"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.010713"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.010582"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.010457"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.010342"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:20:34] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:20:34] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.606762"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.053794"
"1"," "
"1","
"
"1","[101]	train-logloss:0.035555"
"1"," "
"1","
"
"1","[151]	train-logloss:0.028041"
"1"," "
"1","
"
"1","[201]	train-logloss:0.023390"
"1"," "
"1","
"
"1","[251]	train-logloss:0.020437"
"1"," "
"1","
"
"1","[301]	train-logloss:0.018311"
"1"," "
"1","
"
"1","[351]	train-logloss:0.016693"
"1"," "
"1","
"
"1","[401]	train-logloss:0.015508"
"1"," "
"1","
"
"1","[451]	train-logloss:0.014481"
"1"," "
"1","
"
"1","[501]	train-logloss:0.013629"
"1"," "
"1","
"
"1","[551]	train-logloss:0.012996"
"1"," "
"1","
"
"1","[601]	train-logloss:0.012470"
"1"," "
"1","
"
"1","[651]	train-logloss:0.012020"
"1"," "
"1","
"
"1","[701]	train-logloss:0.011636"
"1"," "
"1","
"
"1","[751]	train-logloss:0.011292"
"1"," "
"1","
"
"1","[801]	train-logloss:0.010970"
"1"," "
"1","
"
"1","[851]	train-logloss:0.010693"
"1"," "
"1","
"
"1","[901]	train-logloss:0.010455"
"1"," "
"1","
"
"1","[951]	train-logloss:0.010229"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.010034"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.009858"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.009678"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.009500"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.009370"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.009237"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.009110"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.008990"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.008892"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.008783"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.008686"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:20:48] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:20:48] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684233"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.392073"
"1"," "
"1","
"
"1","[101]	train-logloss:0.254688"
"1"," "
"1","
"
"1","[151]	train-logloss:0.182891"
"1"," "
"1","
"
"1","[201]	train-logloss:0.143781"
"1"," "
"1","
"
"1","[251]	train-logloss:0.120255"
"1"," "
"1","
"
"1","[301]	train-logloss:0.106485"
"1"," "
"1","
"
"1","[351]	train-logloss:0.097070"
"1"," "
"1","
"
"1","[401]	train-logloss:0.092122"
"1"," "
"1","
"
"1","[451]	train-logloss:0.087197"
"1"," "
"1","
"
"1","[501]	train-logloss:0.083741"
"1"," "
"1","
"
"1","[551]	train-logloss:0.080895"
"1"," "
"1","
"
"1","[601]	train-logloss:0.078145"
"1"," "
"1","
"
"1","[651]	train-logloss:0.075911"
"1"," "
"1","
"
"1","[701]	train-logloss:0.073620"
"1"," "
"1","
"
"1","[751]	train-logloss:0.071656"
"1"," "
"1","
"
"1","[801]	train-logloss:0.069754"
"1"," "
"1","
"
"1","[851]	train-logloss:0.068095"
"1"," "
"1","
"
"1","[901]	train-logloss:0.066562"
"1"," "
"1","
"
"1","[951]	train-logloss:0.065243"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.064053"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.062960"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.061773"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.060780"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.059800"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.058801"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.057857"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.057023"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.056272"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.055458"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.054739"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:21:02] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:21:02] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684286"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.393650"
"1"," "
"1","
"
"1","[101]	train-logloss:0.256602"
"1"," "
"1","
"
"1","[151]	train-logloss:0.184254"
"1"," "
"1","
"
"1","[201]	train-logloss:0.145044"
"1"," "
"1","
"
"1","[251]	train-logloss:0.121172"
"1"," "
"1","
"
"1","[301]	train-logloss:0.106134"
"1"," "
"1","
"
"1","[351]	train-logloss:0.096974"
"1"," "
"1","
"
"1","[401]	train-logloss:0.090772"
"1"," "
"1","
"
"1","[451]	train-logloss:0.086053"
"1"," "
"1","
"
"1","[501]	train-logloss:0.082782"
"1"," "
"1","
"
"1","[551]	train-logloss:0.080014"
"1"," "
"1","
"
"1","[601]	train-logloss:0.077232"
"1"," "
"1","
"
"1","[651]	train-logloss:0.074897"
"1"," "
"1","
"
"1","[701]	train-logloss:0.072972"
"1"," "
"1","
"
"1","[751]	train-logloss:0.071213"
"1"," "
"1","
"
"1","[801]	train-logloss:0.069665"
"1"," "
"1","
"
"1","[851]	train-logloss:0.068267"
"1"," "
"1","
"
"1","[901]	train-logloss:0.066952"
"1"," "
"1","
"
"1","[951]	train-logloss:0.065631"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.064324"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.063163"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.062109"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.060982"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.059906"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.058931"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.058051"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.057203"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.056436"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.055753"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.055058"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:21:16] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:21:16] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684207"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.390099"
"1"," "
"1","
"
"1","[101]	train-logloss:0.251134"
"1"," "
"1","
"
"1","[151]	train-logloss:0.178388"
"1"," "
"1","
"
"1","[201]	train-logloss:0.137181"
"1"," "
"1","
"
"1","[251]	train-logloss:0.112995"
"1"," "
"1","
"
"1","[301]	train-logloss:0.098179"
"1"," "
"1","
"
"1","[351]	train-logloss:0.088596"
"1"," "
"1","
"
"1","[401]	train-logloss:0.081979"
"1"," "
"1","
"
"1","[451]	train-logloss:0.077638"
"1"," "
"1","
"
"1","[501]	train-logloss:0.074531"
"1"," "
"1","
"
"1","[551]	train-logloss:0.072037"
"1"," "
"1","
"
"1","[601]	train-logloss:0.069602"
"1"," "
"1","
"
"1","[651]	train-logloss:0.067524"
"1"," "
"1","
"
"1","[701]	train-logloss:0.065707"
"1"," "
"1","
"
"1","[751]	train-logloss:0.064014"
"1"," "
"1","
"
"1","[801]	train-logloss:0.062517"
"1"," "
"1","
"
"1","[851]	train-logloss:0.061157"
"1"," "
"1","
"
"1","[901]	train-logloss:0.059949"
"1"," "
"1","
"
"1","[951]	train-logloss:0.058879"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.057770"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.056786"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.055829"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.054913"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.054139"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.053454"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.052733"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.052037"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.051397"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.050770"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.050235"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:21:29] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:21:29] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.608015"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.082714"
"1"," "
"1","
"
"1","[101]	train-logloss:0.063454"
"1"," "
"1","
"
"1","[151]	train-logloss:0.053971"
"1"," "
"1","
"
"1","[201]	train-logloss:0.047769"
"1"," "
"1","
"
"1","[251]	train-logloss:0.043100"
"1"," "
"1","
"
"1","[301]	train-logloss:0.039564"
"1"," "
"1","
"
"1","[351]	train-logloss:0.036745"
"1"," "
"1","
"
"1","[401]	train-logloss:0.034444"
"1"," "
"1","
"
"1","[451]	train-logloss:0.032476"
"1"," "
"1","
"
"1","[501]	train-logloss:0.030841"
"1"," "
"1","
"
"1","[551]	train-logloss:0.029410"
"1"," "
"1","
"
"1","[601]	train-logloss:0.028203"
"1"," "
"1","
"
"1","[651]	train-logloss:0.027148"
"1"," "
"1","
"
"1","[701]	train-logloss:0.026275"
"1"," "
"1","
"
"1","[751]	train-logloss:0.025436"
"1"," "
"1","
"
"1","[801]	train-logloss:0.024725"
"1"," "
"1","
"
"1","[851]	train-logloss:0.024111"
"1"," "
"1","
"
"1","[901]	train-logloss:0.023469"
"1"," "
"1","
"
"1","[951]	train-logloss:0.022936"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.022455"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.022007"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.021592"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.021174"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.020851"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.020498"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.020194"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.019918"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.019663"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.019413"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.019187"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:21:40] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:21:40] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.608525"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.082410"
"1"," "
"1","
"
"1","[101]	train-logloss:0.063419"
"1"," "
"1","
"
"1","[151]	train-logloss:0.054395"
"1"," "
"1","
"
"1","[201]	train-logloss:0.048254"
"1"," "
"1","
"
"1","[251]	train-logloss:0.043509"
"1"," "
"1","
"
"1","[301]	train-logloss:0.039995"
"1"," "
"1","
"
"1","[351]	train-logloss:0.037183"
"1"," "
"1","
"
"1","[401]	train-logloss:0.034852"
"1"," "
"1","
"
"1","[451]	train-logloss:0.033046"
"1"," "
"1","
"
"1","[501]	train-logloss:0.031572"
"1"," "
"1","
"
"1","[551]	train-logloss:0.030259"
"1"," "
"1","
"
"1","[601]	train-logloss:0.029070"
"1"," "
"1","
"
"1","[651]	train-logloss:0.028027"
"1"," "
"1","
"
"1","[701]	train-logloss:0.027022"
"1"," "
"1","
"
"1","[751]	train-logloss:0.026233"
"1"," "
"1","
"
"1","[801]	train-logloss:0.025475"
"1"," "
"1","
"
"1","[851]	train-logloss:0.024827"
"1"," "
"1","
"
"1","[901]	train-logloss:0.024214"
"1"," "
"1","
"
"1","[951]	train-logloss:0.023621"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.023134"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.022711"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.022269"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.021876"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.021502"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.021161"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.020864"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.020590"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.020300"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.020015"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.019778"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:21:51] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:21:51] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.607752"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.074782"
"1"," "
"1","
"
"1","[101]	train-logloss:0.056866"
"1"," "
"1","
"
"1","[151]	train-logloss:0.049193"
"1"," "
"1","
"
"1","[201]	train-logloss:0.044016"
"1"," "
"1","
"
"1","[251]	train-logloss:0.040288"
"1"," "
"1","
"
"1","[301]	train-logloss:0.037351"
"1"," "
"1","
"
"1","[351]	train-logloss:0.034699"
"1"," "
"1","
"
"1","[401]	train-logloss:0.032676"
"1"," "
"1","
"
"1","[451]	train-logloss:0.030986"
"1"," "
"1","
"
"1","[501]	train-logloss:0.029635"
"1"," "
"1","
"
"1","[551]	train-logloss:0.028394"
"1"," "
"1","
"
"1","[601]	train-logloss:0.027385"
"1"," "
"1","
"
"1","[651]	train-logloss:0.026376"
"1"," "
"1","
"
"1","[701]	train-logloss:0.025549"
"1"," "
"1","
"
"1","[751]	train-logloss:0.024740"
"1"," "
"1","
"
"1","[801]	train-logloss:0.024031"
"1"," "
"1","
"
"1","[851]	train-logloss:0.023385"
"1"," "
"1","
"
"1","[901]	train-logloss:0.022833"
"1"," "
"1","
"
"1","[951]	train-logloss:0.022346"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.021884"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.021466"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.021103"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.020735"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.020389"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.020074"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.019763"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.019485"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.019196"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.018941"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.018724"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:22:00] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:22:00] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684323"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.395587"
"1"," "
"1","
"
"1","[101]	train-logloss:0.261832"
"1"," "
"1","
"
"1","[151]	train-logloss:0.193663"
"1"," "
"1","
"
"1","[201]	train-logloss:0.155243"
"1"," "
"1","
"
"1","[251]	train-logloss:0.134680"
"1"," "
"1","
"
"1","[301]	train-logloss:0.123091"
"1"," "
"1","
"
"1","[351]	train-logloss:0.114873"
"1"," "
"1","
"
"1","[401]	train-logloss:0.109688"
"1"," "
"1","
"
"1","[451]	train-logloss:0.106671"
"1"," "
"1","
"
"1","[501]	train-logloss:0.104003"
"1"," "
"1","
"
"1","[551]	train-logloss:0.101695"
"1"," "
"1","
"
"1","[601]	train-logloss:0.099693"
"1"," "
"1","
"
"1","[651]	train-logloss:0.097942"
"1"," "
"1","
"
"1","[701]	train-logloss:0.096468"
"1"," "
"1","
"
"1","[751]	train-logloss:0.095081"
"1"," "
"1","
"
"1","[801]	train-logloss:0.093773"
"1"," "
"1","
"
"1","[851]	train-logloss:0.092551"
"1"," "
"1","
"
"1","[901]	train-logloss:0.091461"
"1"," "
"1","
"
"1","[951]	train-logloss:0.090470"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.089574"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.088666"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.087836"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.086994"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.086224"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.085447"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.084782"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.084081"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.083410"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.082724"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.082061"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:22:07] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:22:07] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684414"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.398993"
"1"," "
"1","
"
"1","[101]	train-logloss:0.267092"
"1"," "
"1","
"
"1","[151]	train-logloss:0.195339"
"1"," "
"1","
"
"1","[201]	train-logloss:0.156641"
"1"," "
"1","
"
"1","[251]	train-logloss:0.136437"
"1"," "
"1","
"
"1","[301]	train-logloss:0.125368"
"1"," "
"1","
"
"1","[351]	train-logloss:0.118267"
"1"," "
"1","
"
"1","[401]	train-logloss:0.113219"
"1"," "
"1","
"
"1","[451]	train-logloss:0.109735"
"1"," "
"1","
"
"1","[501]	train-logloss:0.107179"
"1"," "
"1","
"
"1","[551]	train-logloss:0.104888"
"1"," "
"1","
"
"1","[601]	train-logloss:0.102930"
"1"," "
"1","
"
"1","[651]	train-logloss:0.101267"
"1"," "
"1","
"
"1","[701]	train-logloss:0.099811"
"1"," "
"1","
"
"1","[751]	train-logloss:0.098308"
"1"," "
"1","
"
"1","[801]	train-logloss:0.096792"
"1"," "
"1","
"
"1","[851]	train-logloss:0.095473"
"1"," "
"1","
"
"1","[901]	train-logloss:0.094215"
"1"," "
"1","
"
"1","[951]	train-logloss:0.093123"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.092028"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.090953"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.090045"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.089179"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.088273"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.087263"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.086346"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.085529"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.084768"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.084170"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.083542"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:22:15] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:22:15] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684350"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.396539"
"1"," "
"1","
"
"1","[101]	train-logloss:0.263335"
"1"," "
"1","
"
"1","[151]	train-logloss:0.187718"
"1"," "
"1","
"
"1","[201]	train-logloss:0.147483"
"1"," "
"1","
"
"1","[251]	train-logloss:0.126451"
"1"," "
"1","
"
"1","[301]	train-logloss:0.114936"
"1"," "
"1","
"
"1","[351]	train-logloss:0.108037"
"1"," "
"1","
"
"1","[401]	train-logloss:0.103413"
"1"," "
"1","
"
"1","[451]	train-logloss:0.099953"
"1"," "
"1","
"
"1","[501]	train-logloss:0.097181"
"1"," "
"1","
"
"1","[551]	train-logloss:0.094879"
"1"," "
"1","
"
"1","[601]	train-logloss:0.092904"
"1"," "
"1","
"
"1","[651]	train-logloss:0.091065"
"1"," "
"1","
"
"1","[701]	train-logloss:0.089140"
"1"," "
"1","
"
"1","[751]	train-logloss:0.087413"
"1"," "
"1","
"
"1","[801]	train-logloss:0.085926"
"1"," "
"1","
"
"1","[851]	train-logloss:0.084524"
"1"," "
"1","
"
"1","[901]	train-logloss:0.083266"
"1"," "
"1","
"
"1","[951]	train-logloss:0.082125"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.081063"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.080022"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.079058"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.078189"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.077334"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.076621"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.075931"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.075274"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.074357"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.073509"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.072803"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:22:22] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:22:22] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.608872"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.103057"
"1"," "
"1","
"
"1","[101]	train-logloss:0.089061"
"1"," "
"1","
"
"1","[151]	train-logloss:0.081352"
"1"," "
"1","
"
"1","[201]	train-logloss:0.075698"
"1"," "
"1","
"
"1","[251]	train-logloss:0.071406"
"1"," "
"1","
"
"1","[301]	train-logloss:0.068045"
"1"," "
"1","
"
"1","[351]	train-logloss:0.065251"
"1"," "
"1","
"
"1","[401]	train-logloss:0.062995"
"1"," "
"1","
"
"1","[451]	train-logloss:0.061036"
"1"," "
"1","
"
"1","[501]	train-logloss:0.059067"
"1"," "
"1","
"
"1","[551]	train-logloss:0.057129"
"1"," "
"1","
"
"1","[601]	train-logloss:0.055585"
"1"," "
"1","
"
"1","[651]	train-logloss:0.054013"
"1"," "
"1","
"
"1","[701]	train-logloss:0.052568"
"1"," "
"1","
"
"1","[751]	train-logloss:0.051291"
"1"," "
"1","
"
"1","[801]	train-logloss:0.049955"
"1"," "
"1","
"
"1","[851]	train-logloss:0.048623"
"1"," "
"1","
"
"1","[901]	train-logloss:0.047588"
"1"," "
"1","
"
"1","[951]	train-logloss:0.046596"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.045478"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.044617"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.043699"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.042919"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.042132"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.041283"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.040580"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.039986"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.039340"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.038700"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.038087"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:22:30] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:22:30] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.609756"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.106148"
"1"," "
"1","
"
"1","[101]	train-logloss:0.090885"
"1"," "
"1","
"
"1","[151]	train-logloss:0.082570"
"1"," "
"1","
"
"1","[201]	train-logloss:0.077354"
"1"," "
"1","
"
"1","[251]	train-logloss:0.073701"
"1"," "
"1","
"
"1","[301]	train-logloss:0.070784"
"1"," "
"1","
"
"1","[351]	train-logloss:0.067789"
"1"," "
"1","
"
"1","[401]	train-logloss:0.065512"
"1"," "
"1","
"
"1","[451]	train-logloss:0.062965"
"1"," "
"1","
"
"1","[501]	train-logloss:0.060651"
"1"," "
"1","
"
"1","[551]	train-logloss:0.058670"
"1"," "
"1","
"
"1","[601]	train-logloss:0.057020"
"1"," "
"1","
"
"1","[651]	train-logloss:0.055553"
"1"," "
"1","
"
"1","[701]	train-logloss:0.053939"
"1"," "
"1","
"
"1","[751]	train-logloss:0.052570"
"1"," "
"1","
"
"1","[801]	train-logloss:0.051467"
"1"," "
"1","
"
"1","[851]	train-logloss:0.050179"
"1"," "
"1","
"
"1","[901]	train-logloss:0.049102"
"1"," "
"1","
"
"1","[951]	train-logloss:0.047915"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.046963"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.045968"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.044933"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.043922"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.042968"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.042075"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.041374"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.040697"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.039999"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.039329"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.038656"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:22:36] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:22:36] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.609129"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.095995"
"1"," "
"1","
"
"1","[101]	train-logloss:0.080322"
"1"," "
"1","
"
"1","[151]	train-logloss:0.072025"
"1"," "
"1","
"
"1","[201]	train-logloss:0.067397"
"1"," "
"1","
"
"1","[251]	train-logloss:0.063394"
"1"," "
"1","
"
"1","[301]	train-logloss:0.060302"
"1"," "
"1","
"
"1","[351]	train-logloss:0.057704"
"1"," "
"1","
"
"1","[401]	train-logloss:0.055413"
"1"," "
"1","
"
"1","[451]	train-logloss:0.053399"
"1"," "
"1","
"
"1","[501]	train-logloss:0.051688"
"1"," "
"1","
"
"1","[551]	train-logloss:0.050126"
"1"," "
"1","
"
"1","[601]	train-logloss:0.048661"
"1"," "
"1","
"
"1","[651]	train-logloss:0.047145"
"1"," "
"1","
"
"1","[701]	train-logloss:0.045809"
"1"," "
"1","
"
"1","[751]	train-logloss:0.044504"
"1"," "
"1","
"
"1","[801]	train-logloss:0.043280"
"1"," "
"1","
"
"1","[851]	train-logloss:0.042108"
"1"," "
"1","
"
"1","[901]	train-logloss:0.041051"
"1"," "
"1","
"
"1","[951]	train-logloss:0.040067"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.039153"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.038317"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.037420"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.036697"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.035919"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.035238"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.034565"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.033941"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.033346"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.032785"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.032297"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:22:43] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:22:43] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684222"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.391338"
"1"," "
"1","
"
"1","[101]	train-logloss:0.253361"
"1"," "
"1","
"
"1","[151]	train-logloss:0.180427"
"1"," "
"1","
"
"1","[201]	train-logloss:0.140204"
"1"," "
"1","
"
"1","[251]	train-logloss:0.115508"
"1"," "
"1","
"
"1","[301]	train-logloss:0.100853"
"1"," "
"1","
"
"1","[351]	train-logloss:0.091016"
"1"," "
"1","
"
"1","[401]	train-logloss:0.083807"
"1"," "
"1","
"
"1","[451]	train-logloss:0.078945"
"1"," "
"1","
"
"1","[501]	train-logloss:0.075310"
"1"," "
"1","
"
"1","[551]	train-logloss:0.072363"
"1"," "
"1","
"
"1","[601]	train-logloss:0.069691"
"1"," "
"1","
"
"1","[651]	train-logloss:0.067571"
"1"," "
"1","
"
"1","[701]	train-logloss:0.065717"
"1"," "
"1","
"
"1","[751]	train-logloss:0.064045"
"1"," "
"1","
"
"1","[801]	train-logloss:0.062506"
"1"," "
"1","
"
"1","[851]	train-logloss:0.061038"
"1"," "
"1","
"
"1","[901]	train-logloss:0.059763"
"1"," "
"1","
"
"1","[951]	train-logloss:0.058652"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.057687"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.056734"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.055778"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.054867"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.053999"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.053185"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.052469"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.051751"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.051038"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.050329"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.049684"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:22:59] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:22:59] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684264"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.392732"
"1"," "
"1","
"
"1","[101]	train-logloss:0.255015"
"1"," "
"1","
"
"1","[151]	train-logloss:0.181559"
"1"," "
"1","
"
"1","[201]	train-logloss:0.140123"
"1"," "
"1","
"
"1","[251]	train-logloss:0.114957"
"1"," "
"1","
"
"1","[301]	train-logloss:0.100329"
"1"," "
"1","
"
"1","[351]	train-logloss:0.090761"
"1"," "
"1","
"
"1","[401]	train-logloss:0.083919"
"1"," "
"1","
"
"1","[451]	train-logloss:0.079064"
"1"," "
"1","
"
"1","[501]	train-logloss:0.075528"
"1"," "
"1","
"
"1","[551]	train-logloss:0.072661"
"1"," "
"1","
"
"1","[601]	train-logloss:0.070131"
"1"," "
"1","
"
"1","[651]	train-logloss:0.067977"
"1"," "
"1","
"
"1","[701]	train-logloss:0.066165"
"1"," "
"1","
"
"1","[751]	train-logloss:0.064510"
"1"," "
"1","
"
"1","[801]	train-logloss:0.062989"
"1"," "
"1","
"
"1","[851]	train-logloss:0.061562"
"1"," "
"1","
"
"1","[901]	train-logloss:0.060438"
"1"," "
"1","
"
"1","[951]	train-logloss:0.059335"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.058262"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.057351"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.056444"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.055537"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.054691"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.053906"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.053164"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.052404"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.051678"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.050936"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.050274"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:23:15] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:23:15] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.684193"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.389335"
"1"," "
"1","
"
"1","[101]	train-logloss:0.249594"
"1"," "
"1","
"
"1","[151]	train-logloss:0.176280"
"1"," "
"1","
"
"1","[201]	train-logloss:0.134633"
"1"," "
"1","
"
"1","[251]	train-logloss:0.109948"
"1"," "
"1","
"
"1","[301]	train-logloss:0.094800"
"1"," "
"1","
"
"1","[351]	train-logloss:0.085058"
"1"," "
"1","
"
"1","[401]	train-logloss:0.077987"
"1"," "
"1","
"
"1","[451]	train-logloss:0.073341"
"1"," "
"1","
"
"1","[501]	train-logloss:0.069910"
"1"," "
"1","
"
"1","[551]	train-logloss:0.067037"
"1"," "
"1","
"
"1","[601]	train-logloss:0.064709"
"1"," "
"1","
"
"1","[651]	train-logloss:0.062737"
"1"," "
"1","
"
"1","[701]	train-logloss:0.060919"
"1"," "
"1","
"
"1","[751]	train-logloss:0.059420"
"1"," "
"1","
"
"1","[801]	train-logloss:0.058096"
"1"," "
"1","
"
"1","[851]	train-logloss:0.056933"
"1"," "
"1","
"
"1","[901]	train-logloss:0.055935"
"1"," "
"1","
"
"1","[951]	train-logloss:0.054992"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.053986"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.053130"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.052316"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.051501"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.050734"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.049991"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.049308"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.048704"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.048158"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.047666"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.047146"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:23:29] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:23:29] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.607904"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.074265"
"1"," "
"1","
"
"1","[101]	train-logloss:0.057856"
"1"," "
"1","
"
"1","[151]	train-logloss:0.049640"
"1"," "
"1","
"
"1","[201]	train-logloss:0.044512"
"1"," "
"1","
"
"1","[251]	train-logloss:0.040460"
"1"," "
"1","
"
"1","[301]	train-logloss:0.037387"
"1"," "
"1","
"
"1","[351]	train-logloss:0.034830"
"1"," "
"1","
"
"1","[401]	train-logloss:0.032649"
"1"," "
"1","
"
"1","[451]	train-logloss:0.030917"
"1"," "
"1","
"
"1","[501]	train-logloss:0.029519"
"1"," "
"1","
"
"1","[551]	train-logloss:0.028325"
"1"," "
"1","
"
"1","[601]	train-logloss:0.027361"
"1"," "
"1","
"
"1","[651]	train-logloss:0.026464"
"1"," "
"1","
"
"1","[701]	train-logloss:0.025598"
"1"," "
"1","
"
"1","[751]	train-logloss:0.024834"
"1"," "
"1","
"
"1","[801]	train-logloss:0.024126"
"1"," "
"1","
"
"1","[851]	train-logloss:0.023513"
"1"," "
"1","
"
"1","[901]	train-logloss:0.022977"
"1"," "
"1","
"
"1","[951]	train-logloss:0.022470"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.022056"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.021630"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.021240"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.020860"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.020542"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.020227"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.019941"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.019664"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.019416"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.019176"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.018945"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:23:40] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:23:40] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.608313"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.074805"
"1"," "
"1","
"
"1","[101]	train-logloss:0.057629"
"1"," "
"1","
"
"1","[151]	train-logloss:0.049628"
"1"," "
"1","
"
"1","[201]	train-logloss:0.044183"
"1"," "
"1","
"
"1","[251]	train-logloss:0.040320"
"1"," "
"1","
"
"1","[301]	train-logloss:0.037451"
"1"," "
"1","
"
"1","[351]	train-logloss:0.035051"
"1"," "
"1","
"
"1","[401]	train-logloss:0.033102"
"1"," "
"1","
"
"1","[451]	train-logloss:0.031619"
"1"," "
"1","
"
"1","[501]	train-logloss:0.030241"
"1"," "
"1","
"
"1","[551]	train-logloss:0.029050"
"1"," "
"1","
"
"1","[601]	train-logloss:0.027980"
"1"," "
"1","
"
"1","[651]	train-logloss:0.027022"
"1"," "
"1","
"
"1","[701]	train-logloss:0.026197"
"1"," "
"1","
"
"1","[751]	train-logloss:0.025425"
"1"," "
"1","
"
"1","[801]	train-logloss:0.024767"
"1"," "
"1","
"
"1","[851]	train-logloss:0.024152"
"1"," "
"1","
"
"1","[901]	train-logloss:0.023576"
"1"," "
"1","
"
"1","[951]	train-logloss:0.023108"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.022651"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.022195"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.021829"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.021464"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.021166"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.020801"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.020508"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.020242"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.019966"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.019692"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.019458"
"1"," "
"1","
"
"2","converting the data into xgboost format..
"
"2","starting with training...
"
"1","[09:23:51] WARNING: amalgamation/../src/learner.cc:541: 
Parameters: { nrounds } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


"
"1","[09:23:51] WARNING: amalgamation/../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
"
"1","[1]	train-logloss:0.607619"
"1"," "
"1","
"
"1","Will train until "
"1",""
"1","train_logloss"
"1",""
"1"," hasn't improved in "
"1",""
"1","50"
"1",""
"1"," rounds.

"
"1","[51]	train-logloss:0.069775"
"1"," "
"1","
"
"1","[101]	train-logloss:0.053792"
"1"," "
"1","
"
"1","[151]	train-logloss:0.046782"
"1"," "
"1","
"
"1","[201]	train-logloss:0.042159"
"1"," "
"1","
"
"1","[251]	train-logloss:0.038709"
"1"," "
"1","
"
"1","[301]	train-logloss:0.036195"
"1"," "
"1","
"
"1","[351]	train-logloss:0.034029"
"1"," "
"1","
"
"1","[401]	train-logloss:0.032107"
"1"," "
"1","
"
"1","[451]	train-logloss:0.030616"
"1"," "
"1","
"
"1","[501]	train-logloss:0.029312"
"1"," "
"1","
"
"1","[551]	train-logloss:0.028069"
"1"," "
"1","
"
"1","[601]	train-logloss:0.027053"
"1"," "
"1","
"
"1","[651]	train-logloss:0.026142"
"1"," "
"1","
"
"1","[701]	train-logloss:0.025358"
"1"," "
"1","
"
"1","[751]	train-logloss:0.024626"
"1"," "
"1","
"
"1","[801]	train-logloss:0.024015"
"1"," "
"1","
"
"1","[851]	train-logloss:0.023430"
"1"," "
"1","
"
"1","[901]	train-logloss:0.022872"
"1"," "
"1","
"
"1","[951]	train-logloss:0.022301"
"1"," "
"1","
"
"1","[1001]	train-logloss:0.021787"
"1"," "
"1","
"
"1","[1051]	train-logloss:0.021299"
"1"," "
"1","
"
"1","[1101]	train-logloss:0.020902"
"1"," "
"1","
"
"1","[1151]	train-logloss:0.020557"
"1"," "
"1","
"
"1","[1201]	train-logloss:0.020264"
"1"," "
"1","
"
"1","[1251]	train-logloss:0.019954"
"1"," "
"1","
"
"1","[1301]	train-logloss:0.019648"
"1"," "
"1","
"
"1","[1351]	train-logloss:0.019331"
"1"," "
"1","
"
"1","[1401]	train-logloss:0.019049"
"1"," "
"1","
"
"1","[1451]	train-logloss:0.018798"
"1"," "
"1","
"
"1","[1500]	train-logloss:0.018581"
"1"," "
"1","
"
